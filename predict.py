import torch
from torchvision import models, transforms
from PIL import Image
import matplotlib.pyplot as plt
import matplotlib.patches as patches
import matplotlib
import os

# --- è¨­å®šåƒæ•¸ ---
CLASSES = ['living', 'non_living']
Chinese_Labels = {'living': 'ç”Ÿç‰© (Living)', 'non_living': 'éç”Ÿç‰© (Non-Living)'}
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
SOURCE_FOLDER = 'test_images'
OUTPUT_FOLDER = 'predict_results'

# --- è¨­å®šä¸­æ–‡å­—å‹ ---
matplotlib.rcParams['font.sans-serif'] = ['Microsoft JhengHei']
matplotlib.rcParams['axes.unicode_minus'] = False


# --- 1. è¼‰å…¥ä½ çš„åˆ†é¡æ¨¡å‹ (è² è²¬åˆ¤æ–·æ˜¯èª°) ---
def load_classifier():
    print("æ­£åœ¨è¼‰å…¥ä½ çš„åˆ†é¡æ¨¡å‹ (ResNet18)...")
    model = models.resnet18(pretrained=False)
    num_ftrs = model.fc.in_features
    model.fc = torch.nn.Linear(num_ftrs, 2)

    try:
        model.load_state_dict(torch.load('living_vs_nonliving.pth', map_location=DEVICE))
    except FileNotFoundError:
        print("éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° model.pth")
        return None
    model = model.to(DEVICE)
    model.eval()
    return model


# --- 2. è¼‰å…¥å®šä½åŠ©æ‰‹ (è² è²¬æ‰¾ä½ç½®) ---
# ä½¿ç”¨ PyTorch å…§å»ºçš„ Faster R-CNNï¼Œå®ƒçœ‹éå¹¾ç™¾è¬å¼µåœ–ï¼Œå¾ˆæœƒæ‰¾æ±è¥¿
def load_detector():
    print("æ­£åœ¨è¼‰å…¥å®šä½åŠ©æ‰‹ (Faster R-CNN)...")
    # ä½¿ç”¨é è¨­æ¬Šé‡ (COCO dataset)
    detector = models.detection.fasterrcnn_resnet50_fpn(pretrained=True)
    detector = detector.to(DEVICE)
    detector.eval()
    return detector


# --- 3. æ ¸å¿ƒåŠŸèƒ½ï¼šæ‰¾å‡ºæœ€æ˜é¡¯çš„ç‰©é«”æ¡†æ¡† ---
def get_dynamic_box(detector, image_tensor, img_w, img_h):
    with torch.no_grad():
        predictions = detector(image_tensor)[0]

    # éæ¿¾ï¼šåªç•™ä¿¡å¿ƒåˆ†æ•¸ > 0.25 çš„æ¡†æ¡†
    keep = predictions['scores'] > 0.25
    boxes = predictions['boxes'][keep].cpu().numpy()

    if len(boxes) > 0:
        # ç­–ç•¥ï¼šå¦‚æœæœ‰å¥½å¹¾å€‹ç‰©é«”ï¼Œæˆ‘å€‘é¸ã€Œé¢ç©æœ€å¤§ã€çš„é‚£ä¸€å€‹
        max_area = 0
        best_box = None

        for box in boxes:
            x1, y1, x2, y2 = box
            area = (x2 - x1) * (y2 - y1)
            if area > max_area:
                max_area = area
                best_box = (x1, y1, x2 - x1, y2 - y1)  # è½‰æˆ x, y, w, h

        return best_box  # å›å‚³æŠ“åˆ°çš„æ¡†æ¡†
    else:
        # å¦‚æœåŠ©æ‰‹çœ¼æ®˜æ²’çœ‹åˆ°æ±è¥¿ï¼Œå°±é€€å›åŸæœ¬çš„ã€Œä¸­é–“ 80%ã€æ–¹æ¡ˆ
        return (img_w * 0.1, img_h * 0.1, img_w * 0.8, img_h * 0.8)


def process_one_image(classifier, detector, image_path, filename):
    # é è™•ç† (çµ¦åˆ†é¡å™¨ç”¨)
    transform_cls = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
    ])

    # é è™•ç† (çµ¦å®šä½åŠ©æ‰‹ç”¨ - åªè¦è½‰ Tensor)
    transform_det = transforms.ToTensor()

    try:
        original_image = Image.open(image_path).convert('RGB')
        img_w, img_h = original_image.size

        # æº–å‚™è³‡æ–™
        input_tensor_cls = transform_cls(original_image).unsqueeze(0).to(DEVICE)
        input_tensor_det = transform_det(original_image).unsqueeze(0).to(DEVICE)

    except Exception as e:
        print(f"ç„¡æ³•è®€å– {filename}: {e}")
        return

    # A. ä½ çš„æ¨¡å‹åˆ¤æ–·é¡åˆ¥
    with torch.no_grad():
        outputs = classifier(input_tensor_cls)
        probabilities = torch.nn.functional.softmax(outputs, dim=1)[0]
        prediction = torch.argmax(probabilities).item()

    class_name = CLASSES[prediction]
    score = probabilities[prediction].item() * 100

    # B. å®šä½åŠ©æ‰‹æ‰¾æ¡†æ¡†
    print(f"æ­£åœ¨åµæ¸¬ {filename} çš„ç‰©é«”ä½ç½®...")
    box_x, box_y, box_w, box_h = get_dynamic_box(detector, input_tensor_det, img_w, img_h)

    # --- ç¹ªåœ– ---
    plt.figure(figsize=(8, 6))
    plt.imshow(original_image)
    ax = plt.gca()

    if class_name == 'living':
        box_color = '#00FF00'
        text_bg = 'green'
    else:
        box_color = '#FF0000'
        text_bg = 'red'

    # ç•«å‡ºå‹•æ…‹æ¡†æ¡†
    rect = patches.Rectangle((box_x, box_y), box_w, box_h,
                             linewidth=3, edgecolor=box_color, facecolor='none', linestyle='--')
    ax.add_patch(rect)

    # æ–‡å­—æ¨™ç±¤ (æ”¾åœ¨æ¡†æ¡†çš„å·¦ä¸Šè§’)
    text_label = f"{Chinese_Labels[class_name]}\nä¿¡å¿ƒ: {score:.1f}%"
    plt.text(box_x, max(box_y - 20, 10), text_label,
             fontsize=12, color='white', fontweight='bold',
             bbox=dict(facecolor=text_bg, alpha=0.7, edgecolor='white', boxstyle='round,pad=0.3'))

    plt.axis('off')
    #plt.title(f"Result: {filename}", fontsize=12)

    save_path = os.path.join(OUTPUT_FOLDER, f"result_{filename}")
    plt.savefig(save_path, bbox_inches='tight', dpi=150)
    print(f"âœ… å®Œæˆ: {filename}")

    print("ğŸ‘‰ è«‹é—œé–‰åœ–ç‰‡è¦–çª—ç¹¼çºŒ...")
    plt.show()


def run():
    if not os.path.exists(SOURCE_FOLDER):
        print(f"éŒ¯èª¤ï¼šæ‰¾ä¸åˆ° '{SOURCE_FOLDER}' è³‡æ–™å¤¾ï¼")
        return
    if not os.path.exists(OUTPUT_FOLDER):
        os.makedirs(OUTPUT_FOLDER)

    # è¼‰å…¥å…©å€‹æ¨¡å‹
    classifier = load_classifier()
    detector = load_detector()  # é€™æ˜¯æ–°çš„

    if classifier is None: return

    image_files = [f for f in os.listdir(SOURCE_FOLDER) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    if not image_files:
        print("æ²’æœ‰åœ–ç‰‡ï¼")
        return

    for img_name in image_files:
        img_path = os.path.join(SOURCE_FOLDER, img_name)
        process_one_image(classifier, detector, img_path, img_name)


if __name__ == '__main__':
    run()